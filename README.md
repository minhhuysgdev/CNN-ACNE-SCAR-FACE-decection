# ğŸ“‹ TÃ i Liá»‡u MÃ´ Táº£ Dá»± Ãn: Acne Classification Using CNN

## ğŸ“Œ Tá»•ng Quan

**Má»¥c tiÃªu:** XÃ¢y dá»±ng mÃ´ hÃ¬nh deep learning sá»­ dá»¥ng CNN Ä‘á»ƒ phÃ¢n loáº¡i cÃ¡c loáº¡i má»¥n, Ä‘á»“ng thá»i giáº£i quyáº¿t váº¥n Ä‘á» máº¥t cÃ¢n báº±ng dá»¯ liá»‡u thÃ´ng qua oversampling vÃ  data augmentation.

**Dataset:** 
- Acne Dataset Image tá»« Kaggle (tiswan14/acne-dataset-image)
- Face Scar Dataset tá»« Kaggle (nayanchaure/face-scar) - Ä‘Ã£ merge vÃ o

**Sá»‘ lá»›p phÃ¢n loáº¡i:** 6 loáº¡i (Ä‘Ã£ thÃªm Scar)
- Blackheads (Má»¥n Ä‘áº§u Ä‘en)
- Cyst (Má»¥n nang)
- Papules (Má»¥n sáº§n)
- Pustules (Má»¥n má»§)
- Scar (Sáº¹o)
- Whiteheads (Má»¥n Ä‘áº§u tráº¯ng)

---

## ğŸ“‚ Cáº¥u TrÃºc Notebook

### **Cell 0:** Metadata
- Link tham kháº£o Ä‘áº¿n Kaggle notebook gá»‘c

### **Cell 1:** Giá»›i thiá»‡u
- MÃ´ táº£ má»¥c tiÃªu cá»§a dá»± Ã¡n

### **Cell 2-4:** Import Libraries vÃ  Setup
- **Cell 2:** CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t (`pip install`)
- **Cell 3:** Header section cho imports
- **Cell 4:** Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t:
  - `tensorflow` vÃ  `keras` cho deep learning
  - `numpy`, `matplotlib` cho xá»­ lÃ½ dá»¯ liá»‡u vÃ  visualization
  - `sklearn` cho class weights computation
  - `kagglehub` Ä‘á»ƒ táº£i dataset

### **Cell 6-12:** Táº£i vÃ  Thiáº¿t Láº­p Dataset
- **Cell 6:** Táº£i 2 datasets tá»« Kaggle sá»­ dá»¥ng `kagglehub`:
  - Acne Dataset Image (tiswan14/acne-dataset-image)
  - Face Scar Dataset (nayanchaure/face-scar)
- **Cell 9:** Kiá»ƒm tra cáº¥u trÃºc dataset face-scar
- **Cell 10:** Reset - XÃ³a táº¥t cáº£ áº£nh Scar Ä‘Ã£ copy trÆ°á»›c Ä‘Ã³ (trÃ¡nh duplicate)
- **Cell 12:** Merge dataset Scar vÃ o train/valid/test vá»›i tá»· lá»‡ 70/15/15
  - Äá»‹nh nghÄ©a cÃ¡c Ä‘Æ°á»ng dáº«n:
    - `base_dir`: ThÆ° má»¥c gá»‘c chá»©a dataset
    - `train_dir`: ThÆ° má»¥c training set
    - `valid_dir`: ThÆ° má»¥c validation set
    - `test_dir`: ThÆ° má»¥c test set
- **Cell 13:** Kiá»ƒm tra láº¡i sá»‘ lÆ°á»£ng áº£nh sau khi merge

### **Cell 17:** Load Datasets
- **ThÃ´ng sá»‘:**
  - `BATCH_SIZE = 32`
  - `IMAGE_SIZE = 128` (128x128 pixels)
- Load datasets vá»›i `image_dataset_from_directory`
- XÃ¡c Ä‘á»‹nh `class_names` tá»« dataset (6 classes sau khi merge Scar)

### **Cell 19:** Visualization
- Hiá»ƒn thá»‹ 9 áº£nh máº«u tá»« training set

### **Cell 21-22:** PhÃ¢n TÃ­ch PhÃ¢n Phá»‘i Dá»¯ Liá»‡u
- Äáº¿m sá»‘ lÆ°á»£ng áº£nh trong má»—i lá»›p
- Nháº­n xÃ©t vá» sá»± máº¥t cÃ¢n báº±ng dá»¯ liá»‡u

### **Cell 24:** TÃ­nh Class Weights
- Sá»­ dá»¥ng `compute_class_weight` vá»›i strategy 'balanced'
- TÃ­nh toÃ¡n trá»ng sá»‘ cho tá»«ng lá»›p Ä‘á»ƒ xá»­ lÃ½ imbalance

### **Cell 26:** Preprocessing
- Normalization: Rescaling pixel values vá» [0, 1] báº±ng cÃ¡ch chia cho 255

### **Cell 28:** Data Augmentation
- **CÃ¡c ká»¹ thuáº­t augmentation:**
  - `RandomFlip`: Láº­t ngang vÃ  dá»c
  - `RandomRotation`: Xoay vá»›i gÃ³c Â±15% (0.15)
  - `RandomZoom`: Zoom vá»›i tá»· lá»‡ Â±15% (0.15)

### **Cell 30:** Oversampling
- Xá»­ lÃ½ lá»›p thiá»ƒu sá»‘ (Whiteheads) báº±ng cÃ¡ch:
  - TÃ¡ch dataset theo tá»«ng lá»›p
  - Tá»± Ä‘á»™ng tÃ¬m minority class (class cÃ³ sá»‘ lÆ°á»£ng Ã­t nháº¥t)
  - Láº·p láº¡i lá»›p thiá»ƒu sá»‘ Ä‘á»ƒ Ä‘áº¡t sá»‘ lÆ°á»£ng báº±ng lá»›p Ä‘a sá»‘ nháº¥t
  - Káº¿t há»£p láº¡i vÃ  shuffle
  - Ãp dá»¥ng data augmentation
  - Batch vÃ  prefetch Ä‘á»ƒ tá»‘i Æ°u performance

### **Cell 32:** Tá»‘i Æ¯u Dataset
- Cache vÃ  prefetch cho validation vÃ  test sets

### **Cell 33-34:** XÃ¢y Dá»±ng MÃ´ HÃ¬nh CNN (ÄÃ£ Cáº£i Tiáº¿n)

#### **Kiáº¿n TrÃºc MÃ´ HÃ¬nh:**

```
Sequential Model (Cáº£i Tiáº¿n):
â”œâ”€â”€ Conv2D(32 filters, 3x3) + ReLU
â”œâ”€â”€ BatchNormalization()  # âœ… Cáº£i tiáº¿n
â”œâ”€â”€ MaxPooling2D(2x2)
â”œâ”€â”€ Conv2D(64 filters, 3x3) + ReLU
â”œâ”€â”€ BatchNormalization()  # âœ… Cáº£i tiáº¿n
â”œâ”€â”€ MaxPooling2D(2x2)
â”œâ”€â”€ Conv2D(128 filters, 3x3) + ReLU
â”œâ”€â”€ BatchNormalization()  # âœ… Cáº£i tiáº¿n
â”œâ”€â”€ MaxPooling2D(2x2)
â”œâ”€â”€ Conv2D(256 filters, 3x3) + ReLU
â”œâ”€â”€ BatchNormalization()  # âœ… Cáº£i tiáº¿n
â”œâ”€â”€ MaxPooling2D(2x2)
â”œâ”€â”€ GlobalAveragePooling2D()  # âœ… Thay Flatten (giáº£m parameters)
â”œâ”€â”€ Dense(256 units) + ReLU + L2 Regularization (0.001)  # âœ… TÄƒng tá»« 128
â”œâ”€â”€ BatchNormalization()  # âœ… Cáº£i tiáº¿n
â”œâ”€â”€ Dropout(0.5)
â””â”€â”€ Dense(6 units) + Softmax
```

#### **ThÃ´ng Sá»‘ Compile:**
- **Optimizer:** Adam (default learning_rate = 0.001)
- **Loss Function:** Sparse Categorical Crossentropy
- **Metrics:** Accuracy

### **Cell 37:** Training

#### **Callbacks:**
1. **EarlyStopping:**
   - Monitor: `val_loss`
   - Patience: 5 epochs
   - `restore_best_weights=True`

2. **ReduceLROnPlateau:**
   - Monitor: `val_loss`
   - Factor: 0.5 (giáº£m learning rate má»™t ná»­a)
   - Patience: 3 epochs
   - Min learning rate: 1e-6

#### **Training Parameters:**
- **Epochs:** 50 (cÃ³ thá»ƒ dá»«ng sá»›m náº¿u EarlyStopping kÃ­ch hoáº¡t)
- **Training Data:** `balanced_ds` (Ä‘Ã£ oversample vÃ  augment)
- **Validation Data:** `valid_ds`
- **Class Weights:** Ãp dá»¥ng Ä‘á»ƒ xá»­ lÃ½ imbalance
- **Verbose:** 2 (hiá»ƒn thá»‹ má»™t dÃ²ng má»—i epoch)

### **Cell 39:** ÄÃ¡nh GiÃ¡ MÃ´ HÃ¬nh
- Evaluate trÃªn test set
- TÃ­nh test accuracy vÃ  loss

### **Cell 41-43:** PhÃ¢n TÃ­ch Káº¿t Quáº£
- **Cell 41:** Thu tháº­p predictions vÃ  true labels tá»« test set
- **Cell 42:** **Confusion Matrix** - Ma tráº­n nháº§m láº«n Ä‘á»ƒ phÃ¢n tÃ­ch lá»—i phÃ¢n loáº¡i
- **Cell 43:** **Classification Report** - BÃ¡o cÃ¡o chi tiáº¿t vá» precision, recall, F1-score cho tá»«ng lá»›p

### **Cell 45:** Visualization Training History
- Váº½ biá»ƒu Ä‘á»“ accuracy vÃ  loss qua cÃ¡c epochs
- So sÃ¡nh training vÃ  validation metrics

### **Cell 47-48:** Test vá»›i áº¢nh Má»›i
- **Cell 47:** Test vá»›i áº£nh Blackheads - Load, preprocess, predict vÃ  hiá»ƒn thá»‹ káº¿t quáº£ vá»›i visualization
- **Cell 48:** Test vá»›i áº£nh Scar - TÆ°Æ¡ng tá»± Cell 47

---

## ğŸ“Š ThÃ´ng Sá»‘ Dataset

### **PhÃ¢n Phá»‘i Dá»¯ Liá»‡u (Sau khi merge Scar vÃ  reset):**

| Class | Train | Validation | Test | Total |
|-------|-------|------------|------|-------|
| **Blackheads** | 735 | 240 | 265 | 1,240 |
| **Cyst** | 645 | 206 | 189 | 1,040 |
| **Papules** | 621 | 209 | 202 | 1,032 |
| **Pustules** | 584 | 217 | 205 | 1,006 |
| **Scar** | 1,219 | 261 | 262 | 1,742 |
| **Whiteheads** | 193 | 49 | 57 | 299 |
| **TOTAL** | **3,997** | **1,182** | **1,180** | **6,359** |

### **Váº¥n Äá» Máº¥t CÃ¢n Báº±ng:**
- Whiteheads chá»‰ cÃ³ 193 áº£nh trong training set (lá»›p thiá»ƒu sá»‘)
- Scar cÃ³ 1,219 áº£nh (lá»›p Ä‘a sá»‘ nháº¥t sau khi merge)
- Tá»· lá»‡: ~6.3:1 (Scar:Whiteheads)
- Papules cÃ³ performance tháº¥p nháº¥t trong test set (Recall = 0.49 sau cáº£i tiáº¿n)

### **Giáº£i PhÃ¡p:**
1. **Oversampling:** TÄƒng sá»‘ lÆ°á»£ng Whiteheads lÃªn ~4,876 (báº±ng vá»›i Scar)
2. **Class Weights:** Ãp dá»¥ng trá»ng sá»‘ tá»± Ä‘á»™ng tÃ­nh tá»« phÃ¢n phá»‘i thá»±c táº¿
3. **Data Augmentation:** TÄƒng Ä‘a dáº¡ng dá»¯ liá»‡u cho táº¥t cáº£ cÃ¡c lá»›p

---

## ğŸ§  Kiáº¿n TrÃºc MÃ´ HÃ¬nh Chi Tiáº¿t

### **Input Shape:**
- `(128, 128, 3)` - áº¢nh RGB 128x128 pixels

### **Convolutional Layers:**

| Layer | Filters | Kernel Size | Activation | Output Shape |
|-------|---------|-------------|------------|--------------|
| Conv2D_1 | 32 | (3, 3) | ReLU | (126, 126, 32) |
| BatchNormalization_1 | - | - | - | (126, 126, 32) |
| MaxPooling2D_1 | - | (2, 2) | - | (63, 63, 32) |
| Conv2D_2 | 64 | (3, 3) | ReLU | (61, 61, 64) |
| BatchNormalization_2 | - | - | - | (61, 61, 64) |
| MaxPooling2D_2 | - | (2, 2) | - | (30, 30, 64) |
| Conv2D_3 | 128 | (3, 3) | ReLU | (28, 28, 128) |
| BatchNormalization_3 | - | - | - | (28, 28, 128) |
| MaxPooling2D_3 | - | (2, 2) | - | (14, 14, 128) |
| Conv2D_4 | 256 | (3, 3) | ReLU | (12, 12, 256) |
| BatchNormalization_4 | - | - | - | (12, 12, 256) |
| MaxPooling2D_4 | - | (2, 2) | - | (6, 6, 256) |

### **Fully Connected Layers:**

| Layer | Units | Activation | Regularization | Dropout |
|-------|-------|------------|----------------|---------|
| GlobalAveragePooling2D | - | - | - | - |
| Dense_1 | 256 | ReLU | L2(0.001) | - |
| BatchNormalization_5 | - | - | - | - |
| Dropout | - | - | - | 0.5 |
| Dense_2 (Output) | 6 | Softmax | - | - |

### **Tá»•ng Sá»‘ Tham Sá»‘:**
- Cáº§n cháº¡y `model.summary()` Ä‘á»ƒ xem chi tiáº¿t sá»‘ lÆ°á»£ng parameters

---

## âš™ï¸ Hyperparameters

### **Data Parameters:**
- `BATCH_SIZE = 32`
- `IMAGE_SIZE = 128`
- `shuffle_buffer_size = 5000` (cho balanced dataset)

### **Model Parameters:**
- **L2 Regularization:** 0.001
- **Dropout Rate:** 0.5
- **Activation Functions:**
  - Convolutional layers: ReLU
  - Output layer: Softmax

### **Training Parameters:**
- **Optimizer:** Adam
- **Initial Learning Rate:** 0.001
- **Loss Function:** Sparse Categorical Crossentropy
- **Max Epochs:** 50 (cÃ³ thá»ƒ dá»«ng sá»›m náº¿u EarlyStopping kÃ­ch hoáº¡t)
- **Class Weights (tá»± Ä‘á»™ng tÃ­nh tá»« dataset sau merge vÃ  reset):**
  - Blackheads: 0.906
  - Cyst: 1.033
  - Papules: 1.073
  - Pustules: 1.141
  - Scar: 0.546
  - Whiteheads: 3.452

### **Callbacks Parameters:**
- **EarlyStopping:**
  - Monitor: `val_loss`
  - Patience: 5
  - Restore best weights: True
  
- **ReduceLROnPlateau:**
  - Monitor: `val_loss`
  - Factor: 0.5
  - Patience: 3
  - Min LR: 1e-6

### **Data Augmentation Parameters:**
- **RandomFlip:** `horizontal_and_vertical`
- **RandomRotation:** 0.15 (Â±15%)
- **RandomZoom:** 0.15 (Â±15%)

---

## ğŸ“ˆ Káº¿t Quáº£ MÃ´ HÃ¬nh (Sau Cáº£i Tiáº¿n)

### **Test Performance:**
- **Test Accuracy:** 76.02%
- **Total Support:** 1,180 áº£nh trong test set

### **Classification Report:**

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| **Blackheads** | 0.75 | 0.82 | 0.78 | 265 |
| **Cyst** | 0.68 | 0.83 | 0.75 | 189 |
| **Papules** | 0.64 | 0.49 | 0.55 | 202 |
| **Pustules** | 0.68 | 0.60 | 0.64 | 205 |
| **Scar** | 0.95 | 0.94 | 0.95 | 262 |
| **Whiteheads** | 0.82 | 0.96 | 0.89 | 57 |
| **Macro Avg** | 0.75 | 0.77 | 0.76 | 1,180 |
| **Weighted Avg** | 0.76 | 0.76 | 0.75 | 1,180 |

### **Nháº­n XÃ©t:**
- âœ… **Scar** cÃ³ performance tá»‘t nháº¥t (F1 = 0.95, Precision = 0.95) - class lá»›n nháº¥t vÃ  dá»… phÃ¢n biá»‡t
- âœ… **Whiteheads** cÃ³ recall ráº¥t cao (0.96) vÃ  precision tá»‘t (0.82) - cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ
- âœ… **Cyst** cÃ³ recall cao (0.83) vÃ  precision tá»‘t hÆ¡n (0.68) - cáº£i thiá»‡n tá»« 0.43
- âœ… **Blackheads** cÃ³ performance tá»‘t (F1 = 0.78) - cáº£i thiá»‡n tá»« 0.57
- âš ï¸ **Papules** váº«n cÃ³ performance tháº¥p nháº¥t (F1 = 0.55, Recall = 0.49) - nhÆ°ng Ä‘Ã£ cáº£i thiá»‡n tá»« 0.34
- âš ï¸ **Pustules** cÃ³ performance trung bÃ¬nh (F1 = 0.64) - cáº£i thiá»‡n tá»« 0.51
- ğŸ“Š Overall accuracy: 76% - **cáº£i thiá»‡n 2%** so vá»›i model trÆ°á»›c (74%)
- ğŸ“Š Macro F1-score: 0.76 - **cáº£i thiá»‡n 0.15** so vá»›i model trÆ°á»›c (0.61)
- ğŸ“Š Weighted F1-score: 0.75 - tÆ°Æ¡ng Ä‘Æ°Æ¡ng model trÆ°á»›c nhÆ°ng vá»›i dataset Ä‘Ã£ reset

---

## ğŸ”§ CÃ¡c Ká»¹ Thuáº­t ÄÆ°á»£c Sá»­ Dá»¥ng

### **1. Xá»­ LÃ½ Imbalanced Data:**
- âœ… Oversampling lá»›p thiá»ƒu sá»‘ (Whiteheads)
- âœ… Class weights trong training
- âœ… Data augmentation

### **2. Regularization:**
- âœ… L2 Regularization (0.001) trong Dense layer
- âœ… Dropout (0.5) Ä‘á»ƒ giáº£m overfitting
- âœ… BatchNormalization sau má»—i Conv2D vÃ  Dense layer - giÃºp training á»•n Ä‘á»‹nh vÃ  nhanh hÆ¡n

### **3. Optimization:**
- âœ… Adam optimizer vá»›i adaptive learning rate
- âœ… Learning rate scheduling (ReduceLROnPlateau)
- âœ… Early stopping Ä‘á»ƒ trÃ¡nh overfitting

### **4. Data Pipeline Optimization:**
- âœ… Dataset caching
- âœ… Prefetch Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ training
- âœ… Batch processing
- âœ… Parallel processing cho data augmentation

### **5. Tá»‘i Æ¯u HÃ³a Tá»‘c Äá»™ Training:**
- âœ… GPU Metal (MPS) cho Mac Apple Silicon - nhanh hÆ¡n 5-10x so vá»›i CPU (náº¿u cÃ³)
- âœ… Mixed Precision Training (float16) - giáº£m memory vÃ  tÄƒng tá»‘c Ä‘á»™ 2x (náº¿u cÃ³ GPU)
- âœ… Dataset pipeline optimization vá»›i prefetch vÃ  caching

---

## ğŸ“ Ghi ChÃº Quan Trá»ng

1. **Dataset Path:** Dataset Ä‘Æ°á»£c táº£i vá» tá»« Kaggle vÃ  lÆ°u táº¡i cache directory cá»§a kagglehub
2. **Normalization:** Pixel values Ä‘Æ°á»£c normalize vá» [0, 1] trÆ°á»›c khi training
3. **Data Augmentation:** Chá»‰ Ã¡p dá»¥ng cho training set, khÃ´ng Ã¡p dá»¥ng cho validation/test
4. **Class Weights:** ÄÆ°á»£c tÃ­nh toÃ¡n dá»±a trÃªn phÃ¢n phá»‘i ban Ä‘áº§u cá»§a training set
5. **Oversampling:** Chá»‰ Ã¡p dá»¥ng cho training set, validation vÃ  test giá»¯ nguyÃªn phÃ¢n phá»‘i gá»‘c

---

### **ÄÃ£ thá»±c hiá»‡n:**
- âœ… **BatchNormalization:** ÄÃ£ thÃªm sau má»—i Conv2D vÃ  Dense layer
- âœ… **GlobalAveragePooling2D:** ÄÃ£ thay tháº¿ Flatten Ä‘á»ƒ giáº£m parameters
- âœ… **TÄƒng Dense units:** Tá»« 128 lÃªn 256 Ä‘á»ƒ tÄƒng capacity
- âœ… **Reset dataset:** ÄÃ£ xÃ³a duplicate Scar images

---

## ğŸ“š Tham Kháº£o

- **Dataset:** [Kaggle - Acne Dataset Image](https://www.kaggle.com/datasets/tiswan14/acne-dataset-image)
- **Original Notebook:** [Kaggle Notebook](https://www.kaggle.com/code/zulqarnain11/acne-classification-using-cnn)
- **Framework:** TensorFlow/Keras
- **Python Version:** 3.13

---

*TÃ i liá»‡u Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng tá»« notebook `acne-classification-using-cnn.ipynb`*

